I tried to implement a Residual connection neural network and recreate Lenet-5, and can't set up architecture
Here is Residual connection block Here's architecture I tried to change the sizes of the input and output channels, but nothing worked I've made some modifications to your code: and Move the self.activation(self.conv(x) + self.correct_channels(x)) line to the ResidualBlock class for clarity. Add x = x.view(x.shape[0], -1) to flatten the extracted convolutional features. The size of self.lin1 depends on the size of your input tensor. In the provided code, I assumed the input size to be [8, 1, 256, 256] . Since you use torch.nn.MaxPool2d twice in your model, the tensor size would be [8, 120, 64, 64] after passing through self.conv3 . Consequently, the tensor size would change to [8, 491520] (120 * 64 * 64 = 491520) after passsing through x.view(x.shape[0], -1) , so it requires the adjustment in self.lin1 to torch.nn.Linear(in_features=120*64*64, out_features=84) . Similarly, if your input tensor shape differs, such as [8, 1, 1000, 1000] , you should set self.lin1 as torch.nn.Linear(in_features=120*250*250, out_features=84) . For more information about LeNet-5, you can refer this repository: https://github.com/ChawDoe/LeNet5-MNIST-PyTorch/blob/master/model.py