Consider the case of a multiclass classification problem with 12 classes (classes 0 to 11). These classes are nominal categorical variables (no ranking order). I have trained two models ( M1 and M2 ), as follows: M1 : The output vector, y_train , is provided in one-hot-encoded format: M2 : The output vector, y_train , is provided as integer values. I have trained these models with RandomForestClassifier and MLPClassifier . Below you can see the code of the two models for the Random Forest (the codes for the MLP are exactly the same, just changing the Classifier type). Code for M1 : and this for M2 : Are these codes technically correct or am i missing something? I am asking this, because so far i have found that in the case of a multiclass problem, the M1 approach (one-hot-encode output) is the correct/suitable one.  But, i am getting a higher f1-score in the y_test set, for the M2 approach. While M1 is 0.73 , the M2 gives me 0.77 . This also happened when i use MLPClassifier . The M1 for MLPClassifier is 0.73 while for M2 is 0.76 . EDIT: Here is the M1 MLP: and here he M2 : The main difference between one-hot-encoding and integer-encoding is based on the ordinal relationship between the classes. It means when you apply one-hot-encoding on classes, the distance between class 4 and 5 is equal to the distance of class 4 and 10. So, both of your approach is totally correct and making the decision of which approach should be taken, is with the nature of your data, but you should note that for classification purpose between multi classes, in many cases, one-hot-encoding can give you the better result(because many ML algorithms are better to work with that such as SVM )