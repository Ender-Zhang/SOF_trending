The setup: I use a sequence-to-sequence model in Pytorch to predict the next token, using a sequence of prior tokens. It uses the same vocabulary for the encoder and the decoder. The model is trained by batches of (src, trg) pairs of tensors of the same length (for teacher_forcing), although the trg tensor consists of one token and the rest is "" indices, which are ignored by the loss function. The problem: My friend, who is much more seasoned ML engineer, has reviewed my assignment and was not quite sure if I should embed the decoder input sequence. I tried digging into the question a bit, but it seems that almost all of the examples of seq2seq models that I could find are built for translation, so it would have two different embeddings for each language in decoder and encoder respectively. Below is the model code: and the training script: In addition, model training has yielded no results: loss function (Cross entropy) just fluctuates. I have tried several combinations of hyperparameters, including removal of gradient clipping, but to no avail. Here's the loss graph: