I have the following problem: A certain producer sends Protobuf messages as binary data (byte array). These binary data enter a misconfigured Kafka cluster which deserializes the byte array as string. Then, that cluster serializes the data as string and sends it to the consumer . The unsuspecting consumer expects to receive a binary byte array, but instead gets a UTF-8 encoded mess. I tried to reproduce it in a JUnit test. Let's say we have the following proto file: Then I wrote the following test. The producer creates a Protobuf message msg and encodes it as a byte array bytesSentByProducer . The misconfigured Kafka cluster receives that byte array, deserializes it as string dataReceivedInsideMisconfiguredKafka , serializes it as string dataSentToConsumer and sends it to the consumer. Because UTF-8 encoding has corrupted the binary data, the call results in an exception: The conversion of byte array back to the message works with uncorrupted byte array bytesSentByProducer ( MyMessage.parseFrom(bytesSentByProducer) ). Questions: Is it possible to convert dataSentToConsumer to bytesSentByProducer ? If yes, how can I fix this issue if the only part under my control is the consumer? How can I undo the UTF-8 encoding which happens inside the misconfigured Kafka cluster? Note: The obvious solution is to configure the Kafka cluster properly. The same consumer works fine in another environment where there is a normal Kafka cluster which doesn't do any strange transformation. This obvious and easiest solution is not available for bureaucratic reasons. What I tried Approach 1 The result is an exception. Approach 2 As far as I know UTF-8 has various byte patterns: 0xxxxxxx for single-byte characters. 110xxxxx 10xxxxxx for two-byte characters etc. I assume that somewhere inside StringDeserializer and/or StringSerializer binary data are modified to conform to such UTF-8 rules. Provided that this transformation is reversible, one could manipulate bits to get the original message. Hate to be the bearer of bad news, but what you want is impossible. The key point is completeness . Is there a complete mapping from one domain (here, raw bytes) to the target domain (here, UTF_8), and, the same in reverse. Said differently: Here's the challenge: Given an arbitrarily chosen sequence of bytes, make some text such that, if you serialize that text using UTF-8 charset encoding, it produces those exact bytes. Is there a sequence of bytes you can choose such that this job is not possible ? And unfortunately the answer is yes , thus trivially proving that bytes -> text-via-UTF_8 -> bytes is fatal unless you're very very lucky and the bytes so happen to not include anything that UTF8 cannot render. Many decoders will take non-valid-UTF8 (because, if certain byte sequences cannot possibly appear when converting text to bytes with UTF8, generally that implies there are certain byte sequences which, if converted to text via UTF8, are invalid) - and just take a stab at it, or toss the 'corrupted data' glyph in there instead of erroring out. So, whomever manages that Kafka server never got an error. This act (turning invalid UTF-8, because it wasn't UTF-8, into a 'uhh, wha?' symbol) is destructive . Some charset encodings do make this possible. The most commonly used one is no doubt ISO-8859-1 . That one is complete - because it's just a simple mapping that maps every byte value, all the way from 0 to 255, to some unique character. Hence, you can go two-way on that all day. Thus, we get to some fixes: base64 survives just about everything, that's what is was designed for. It costs 33% efficiency (base64 turns 3 bytes into 4 bytes; input 3MB large turns into 4MB large output). Hand your bytes in base64 encoded form to the kafka thing, or make kafka do it. Set up every chain in the link that applies charset encoding (so everywhere that bytes turn into chars or vice versa) to use ISO-8859-1. This is hacky and weird and not recommended, but might be a 'quick' fix for some definition of the word 'quick'. Fix it properly - which, at this point, I'm sure you already know how to do, you're just asking for faster solutions and/or ways to still process already corrupted data. Which is where the first sentence of this answer comes in :( Provided that this transformation is reversible Yup. You correctly identified the key requirement for all of this, which is that it's reversible. And it isn't, unfortunately.