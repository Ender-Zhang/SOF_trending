Im making a quicksort for an assignment but it always throws a stack overflow when sorting large lists (>100.000 items). A stack overflow is supposed to indicate that the stop condition is incorrect but i cant find the issue. I would really appreciate some help. Thanks for reading.
My quicksort: I have tried various different implementations, none of them working. I have tried to increase the stack size. If your data contains sorted runs, then a quicksort of n items will need O(n) stack frames. Even if there are only some sorted runs, this can be an issue. There are several solutions to this. The simplest approach is simply swap the pivot with a random element before using it. You will now do O(n) work in generating O(n) pseudorandom choices. But it now becomes almost impossible to trigger quicksort's potential pathological behavior. The solution that is most commonly used these days is to use another sorting algorithm. Timsort is a popular choice because its worst case behavior is O(n log(n)) , but it can find and take advantage of sorted sequences to get time O(n) in a lot of common real world scenarios. I wrote about the pitfalls of implementing Quicksort a while ago on my blog . Looking at your implementation: You seem to be using the Lomuto partitioning scheme (two-way partitioning). This means arrays with many duplicates will trigger Quicksort's worst case, where one partition is trivial (single element / no element) and the other partition contains all remaining elements. This may then require linear stack size in the length of the array, leading to a stack overflow. I suggest switching to a three-way partitioning ("dutch flag sort") into elements smaller, equal and larger than the pivot; you only need to recursively sort the "smaller" and "larger" partitions then. You always pick the last element as the pivot. This means that for sorted arrays, the worst case will occur: One partition is trivial, the other contains all elements but one. An easy solution, as already pointed out by others, is to randomize the choice of pivot; that way, you can achieve expected O(n log n) runtime. Furthermore, you could - and should - implement an easy trick to bound the stack usage: Sort the smaller partition first , then sort the other partition via a tail call, using no stack space. Unfortunately, Java has no proper tail calls, so you'd have to opt for an iterative implementation: Use a stack of "jobs" where your Job class is just an array "slice" / range (two integers: start & end index of the slice). Initially, push the Job (0, n), where n is the array length, then do "recursive calls" by pushing jobs (from, to). An iterative implementation will avoid stack overflows altogether, but you may still want to bound the auxiliary space usage - to do so, push larger job first . The rationale behind this is that we want smaller jobs to be on top since we can finish them using less auxiliary space; it can be shown that if you do this, your job stack will at most have size O(log n). If you are free to implement another sorting algorithm, I'd recommend Merge Sort which I believe is the simplest efficient sorting algorithm (assuming you're allowed linear auxiliary space usage) or Heap Sort (which is in-place and also achieves O(n log n) time complexity, yet is still quite simple).