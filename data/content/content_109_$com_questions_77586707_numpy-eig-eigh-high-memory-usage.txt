Let me start with a disclaimer that I am not as experienced in Python as one might want to be, so it could be that this is being caused by something I had caused myself. Disclaimer aside, I've noticed some strange behavior in terms of the memory usage in NumPy. Specifically, when performing eigenvalue decompositions (I request both eigenvalues and eigenvectors) the memory usage is significantly larger than expected. This becomes a problem when the matrix size is such that we can not afford to store several copies. A typical LAPACK implementation (which NumPy calls -- at some point) will compute the eigenvectors in place, thus the memory requirement will be roughly 8N^2+O(N) -- with the 8 coming from the double precision floating point data type used in my case. Thus, with NumPy being supposedly relatively efficient one would expect something similar. Admittedly, we know to expect twice as much, as NumPy will keep the original matrix, so it must at some point make at least a single copy. Interestingly, this is most definitely not what is observed. As an example, we can track the memory usage, as reported by /proc/<pid>/status , of the following code (using Python 3.9.7, NumPy 1.26.2, SciPy 1.11.3): For reference, the following tests were performed on a node with 2x AMD EPYC 7702 with OMP_NUM_THREADS=16 running Debian bullseye (Linux 5.10.0-26-amd64), though I don't expect this to be relevant to anything other than the runtime in the plots, which is irrelevant to the problem at hand. Looking at the time between the two dashed vertical lines, where the numpy.linalg.eigh call takes place, we observe higher memory usage than expected. The horizontal lines represent the expected size of a matrix of our chosen size. We see that, on top of the single copy we expect, we get two more copies roughly half-way through the calculation. Furthermore, at the very end there appears to be another copy being created, presumably as something is being copied as opposed to moved. In short, we've gone from 2 times the size to 5 times. So my question is, why does this happen and how, if possible, can it be resolved? Ideally I would also avoid having the original copy but as far as I understand this was considered at some point but not implemented in NumPy, so I assume that is not possible at the moment. Curiously, replacing numpy.linalg.eigh with numpy.linalg.eig , we see even worse performance at the end (not only in time, which is expected, but also in the memory use). At first we see the same behavior, though half-way through we only get one more copy this time around, however at the very end we appear to incur a significantly greater overhead with an additional 4 temporary copies (in terms of the memory use, whether or not that is the result of 4 copies I do not know) being created. I would assume this is some sort of bug in the implementation of NumPy, at the very least that peak at the very end? Particularly in light of what happens if we try a different implementation, which also uses the LAPACK backend. We can swap to SciPy ( scipy.linalg.eigh ), which offers similar functions (though slightly worse performance it seems), which do not suffer from the same peak in memory use at the very end, though we still have 3 copies, which is still not ideal. SciPy also allows us to use the option overwrite_a=True , which should, according to the documentation, overwrite the matrix. As far as I understand this should then lead to the expected memory behavior in line with what one would observe in C/C++/Fortran, but in practice it does nothing. Indeed, we see roughly identical behavior as without this setting, both in terms of time and space. TL;DR How to get the eigenvalues and eigenvectors of a real symmetric matrix in Python with minimal memory use, both NumPy and SciPy appear to have quite some overhead with NumPy being significantly worse? EDIT 1 Potentially relevant links so far: How to predict memory requirement for np.linalg.inv? -  discusses a similar issue for the inverse, however only for the 3x memory usage in the majority of the algorithm. Does not discuss the peak at the very end. https://github.com/numpy/numpy/issues/14024 -  seems to only mention a 2x memory usage due to the copy, that feature request has not been implemented (so it seems), but that only explains a small part of the observed memory usage and I don't think is particularly relevant. They also mention overwrite_a not doing anything for the memory usage in SciPy, which seems to have remained true.