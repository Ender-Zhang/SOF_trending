Doing an ML thing yesterday, my team found that we wanted to encode some numbers into vectors consisting of run of 1s with length equal to the whole part, plus one more element for the fractional part, plus some number of padding 0s.  Thus for example the number 3.5 is unpacked into a vector like so: [1, 1, 1, 0.5, 0, ..., 0] (it makes sense in context, I promise).  So, now we have some functions for packing and unpacking numbers to and from this representation and we want to name them in the standard way, only we can't figure out what that is. This is a little bit like a one-hot encoding, but it's not that similar: we have multiple hot bits and also usually one warm bit.  It's a lot like a unary number representation, except for the fractional part and the padding zeroes.  In practice the implementation is just a vector fill.  None of these connections are getting me anywhere on Google. This representation is natural enough in our domain that I'm sure we're not the first people to think of it, so there must be some prior art somewhere.  But where?