I am trying to do image augmentation using keras and tensorflow. However, i couldn't understand the impact of batch_size parameter on the augmented data. I gave 1 image as input, code ran for 3 times, my output were only 3 images (code attached below). I have tried to change batch_size and iterations multiple times, even chatgpt says, i should have 6 images (3 iterations, 2 batch_size) as output in this case. Anyhow, my idea was output image (for one image input) =  batch_size  * 1 (for each iteration)
so if batch_size isn't a multiplier per image input, then what is its purpose? or what am i missing? further info regarding code: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html According to the docs , ImageDataGenerator provides a generator that generates batches of data. flow would take an array of images, and each time you iterate over the generator (with a for loop, list comprehension, or similar), it would output a batch of images. You can control the size of the batch with the batch_size parameter. So if you have an array x with 100 images in it, .flow(x, batch_size=32) would give you 32 different augmented images in batch on each loop iteration. If you have fewer images than the batch size, they will not be output multiple times to fill up batch_size . Additionally, if you use a Generator, tf.Dataset or similar, you don't specify a batch_size in model.fit() , as the data already comes in batches. ( Link , info box for batch_size ) One info though, in the docs it is stated that ImageDataGenerator is deprecated: Deprecated: tf.keras.preprocessing.image.ImageDataGenerator is not
recommended for new code. Prefer loading images with
tf.keras.utils.image_dataset_from_directory and transforming the
output tf.data.Dataset with preprocessing layers. For more
information, see the tutorials for loading images and augmenting
images, as well as the preprocessing layer guide.